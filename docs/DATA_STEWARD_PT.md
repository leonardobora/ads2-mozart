# üìä Guia do Data Steward - Projeto Mozart

## Vis√£o Geral
Como **Data Steward** do projeto de classifica√ß√£o de conte√∫do sens√≠vel em letras musicais, voc√™ √© respons√°vel pela gest√£o, qualidade e prepara√ß√£o dos dados que alimentar√£o nossa rede neural CNN.

---

## üéØ Suas Responsabilidades

### 1. **Coleta e Aquisi√ß√£o de Dados**
- Baixar e validar datasets de letras musicais
- Garantir integridade dos dados brutos
- Documentar proveni√™ncia dos dados

### 2. **Qualidade e Limpeza**
- Identificar e corrigir inconsist√™ncias
- Remover duplicatas e dados corrompidos
- Validar formatos e estruturas

### 3. **Anota√ß√£o de Conte√∫do Sens√≠vel**
- Rotular manualmente conte√∫do problem√°tico
- Classificar: misoginia, viol√™ncia, depress√£o, suic√≠dio, racismo, homofobia
- Garantir consist√™ncia na anota√ß√£o
- Documentar crit√©rios utilizados

### 4. **Prepara√ß√£o para ML**
- Criar splits treino/valida√ß√£o/teste
- Normalizar formatos de texto
- Gerar datasets rotulados prontos para a CNN

---

## üöÄ Passo a Passo - Prepara√ß√£o dos Dados

### **ETAPA 1: Configura√ß√£o do Ambiente**

```bash
# 1. Clone o reposit√≥rio (se necess√°rio)
cd /home/leonardobora/mozart_aps2

# 2. Instale as depend√™ncias
pip install -r requirements.txt

# 3. Verifique se o ambiente est√° funcionando
python -c "import pandas as pd; import numpy as np; print('‚úÖ Ambiente OK')"
```

### **ETAPA 2: Download dos Dados**

```bash
# Execute o script de download
python scripts/download_data.py

# Verifique se os dados foram baixados
ls -la data/raw/
```

**‚ùó O que verificar:**
- Arquivo CSV foi criado em `data/raw/`
- N√£o h√° erros de conex√£o ou autentica√ß√£o
- Dataset cont√©m as colunas esperadas: title, artist, year, lyrics

### **ETAPA 3: Explora√ß√£o Inicial dos Dados**

```bash
# Execute o notebook de explora√ß√£o
jupyter notebook notebooks/01_data_exploration.ipynb
```

**üìã Checklist de Valida√ß√£o:**
- [ ] Dataset tem entre 5.000-10.000 m√∫sicas
- [ ] Per√≠odo temporal: 1959-2019
- [ ] Letras em ingl√™s e portugu√™s
- [ ] Sem campos vazios cr√≠ticos
- [ ] Distribui√ß√£o temporal equilibrada

### **ETAPA 4: An√°lise de Qualidade dos Dados**

```python
# Execute este c√≥digo para an√°lise detalhada
from src.data.data_loader import MusicDataLoader

loader = MusicDataLoader()
df = loader.load_local_csv('data/raw/kaggle_brianblakely_top-100-songs-and-lyrics-from-1959-to-2019.csv')

# Verifique a qualidade
is_valid, issues = loader.validate_dataset(df)
print(f"Dataset v√°lido: {is_valid}")
if issues:
    print("Problemas encontrados:", issues)
```

### **ETAPA 5: Pr√©-processamento de Texto**

```bash
# Execute o script de pr√©-processamento
python scripts/data_preprocessing.py --input data/raw/ --output data/processed/
```

**üîß O que este script faz:**
- Remove caracteres especiais desnecess√°rios
- Normaliza encodings (UTF-8)
- Padroniza formatos de data/ano
- Remove duplicatas exatas
- Cria colunas derivadas (word_count, char_count)

### **ETAPA 6: Cria√ß√£o dos Splits de Dados**

```python
# Execute para criar divis√µes treino/teste
from src.data.splitter import create_stratified_split

# Carregue os dados processados
df = pd.read_csv('data/processed/music_lyrics_cleaned.csv')

# Crie os splits
train_df, val_df, test_df = create_stratified_split(
    df, 
    test_size=0.2, 
    val_size=0.1,
    stratify_by='decade'  # Equilibra por d√©cada
)

# Salve os splits
train_df.to_csv('data/processed/train_data.csv', index=False)
val_df.to_csv('data/processed/val_data.csv', index=False)
test_df.to_csv('data/processed/test_data.csv', index=False)
```

### **ETAPA 7: Prepara√ß√£o para Rotula√ß√£o**

```bash
# Crie arquivo para rotula√ß√£o manual
python scripts/create_labeling_template.py --sample 1000 --output data/labeled/
```

**üìù Arquivo de rotula√ß√£o criado:**
- `data/labeled/songs_to_label.csv`
- Cont√©m 1000 m√∫sicas selecionadas aleatoriamente
- Colunas para rotular: misogyny, violence, depression, suicide, racism, homophobia

### **ETAPA 8: Anota√ß√£o Manual de Conte√∫do Sens√≠vel**

**üéØ Processo de Anota√ß√£o:**

1. **Abra o arquivo de rotula√ß√£o:**
```bash
# Use Excel, LibreOffice ou editor de sua prefer√™ncia
libreoffice data/labeled/songs_to_label.csv
```

2. **Leia as instru√ß√µes completas:**
```bash
cat data/labeled/INSTRUCTIONS_PT.md
```

3. **Para cada m√∫sica, analise a coluna `lyrics_preview` e preencha:**
   - **misogyny**: 0 ou 1
   - **violence**: 0 ou 1  
   - **depression**: 0 ou 1
   - **suicide**: 0 ou 1
   - **racism**: 0 ou 1
   - **homophobia**: 0 ou 1
   - **annotator_id**: Seu nome/iniciais
   - **confidence**: 1-5 (n√≠vel de certeza)

4. **Crit√©rios de Qualidade:**
   - ‚úÖ Rotule pelo menos 800 m√∫sicas (de 1000)
   - ‚úÖ Mantenha consist√™ncia nos crit√©rios
   - ‚úÖ Use confidence baixa quando incerto
   - ‚úÖ Adicione notas em casos especiais

5. **Salve o arquivo anotado:**
```bash
# Salve como: data/labeled/songs_labeled_COMPLETE.csv
```

### **ETAPA 9: Valida√ß√£o da Anota√ß√£o**

```python
# Execute para validar sua anota√ß√£o
import pandas as pd

# Carregue dados anotados
df_labeled = pd.read_csv('data/labeled/songs_labeled_COMPLETE.csv')

# Estat√≠sticas da anota√ß√£o
labels = ['misogyny', 'violence', 'depression', 'suicide', 'racism', 'homophobia']
print("üìä Estat√≠sticas da Anota√ß√£o:")
for label in labels:
    if label in df_labeled.columns:
        count = df_labeled[label].sum()
        total = df_labeled[label].notna().sum()
        print(f"   {label}: {count}/{total} ({count/total*100:.1f}%)")

# Verificar qualidade
missing_annotations = df_labeled[labels].isnull().sum().sum()
print(f"\n‚ö†Ô∏è Anota√ß√µes faltando: {missing_annotations}")

# Confian√ßa m√©dia
if 'confidence' in df_labeled.columns:
    avg_confidence = df_labeled['confidence'].mean()
    print(f"üéØ Confian√ßa m√©dia: {avg_confidence:.1f}/5")
```

---

## üìã Checklist Final - Data Steward

### **Dados Brutos** ‚úÖ
- [ ] Dataset baixado com sucesso
- [ ] Proveni√™ncia documentada
- [ ] Backup criado em local seguro
- [ ] Metadados registrados

### **Qualidade dos Dados** ‚úÖ
- [ ] Valida√ß√£o autom√°tica passou
- [ ] Duplicatas removidas
- [ ] Campos obrigat√≥rios preenchidos
- [ ] Encoding padronizado (UTF-8)
- [ ] Distribui√ß√£o temporal verificada

### **Dados Processados** ‚úÖ
- [ ] Splits criados (70% treino, 20% teste, 10% valida√ß√£o)
- [ ] Estratifica√ß√£o por d√©cada aplicada
- [ ] Arquivo de rotula√ß√£o preparado
- [ ] Documenta√ß√£o atualizada

### **Anota√ß√£o de Conte√∫do** ‚úÖ
- [ ] Pelo menos 800 m√∫sicas anotadas
- [ ] Crit√©rios de classifica√ß√£o documentados
- [ ] Confian√ßa m√©dia > 3.0
- [ ] Arquivo `songs_labeled_COMPLETE.csv` salvo
- [ ] Valida√ß√£o estat√≠stica executada

### **Prepara√ß√£o para CNN** ‚úÖ
- [ ] Formato compat√≠vel com pipeline ML
- [ ] Dados rotulados prontos para treinamento
- [ ] Vocabul√°rio extra√≠do
- [ ] Features num√©ricas normalizadas

---

## üö® Problemas Comuns e Solu√ß√µes

### **Erro: "kagglehub not found"**
```bash
pip install kagglehub[pandas-datasets]
```

### **Erro: "Dataset muito pequeno"**
- Verifique conex√£o com internet
- Confirme nome do dataset Kaggle
- Tente download manual

### **Erro: "Encoding problems"**
```python
# Force UTF-8 encoding
df = pd.read_csv('file.csv', encoding='utf-8', errors='ignore')
```

### **Erro: "Duplicatas n√£o removidas"**
```python
# Remove duplicatas manuais
df = df.drop_duplicates(subset=['title', 'artist'], keep='first')
```

---

## üìû Pr√≥ximos Passos

Ap√≥s completar estas etapas, entregue para a equipe:

1. **Arquivo `data/processed/train_data.csv`** - Dados de treino limpos
2. **Arquivo `data/processed/test_data.csv`** - Dados de teste  
3. **Arquivo `data/labeled/songs_labeled_COMPLETE.csv`** - Dados anotados para treinamento
4. **Relat√≥rio de qualidade** - Salvem `logs/data_quality_report.txt`
5. **Estat√≠sticas de anota√ß√£o** - Distribui√ß√£o dos r√≥tulos

**üîÑ Contato com outros membros:**
- **ML Engineer**: Entregar dados rotulados prontos para CNN
- **DevOps**: Verificar pipelines de dados
- **Supervisor**: Relat√≥rio de qualidade da anota√ß√£o

---

## üìö Recursos Adicionais

- **Documenta√ß√£o t√©cnica**: `docs/data_format.md`
- **Scripts √∫teis**: `scripts/`
- **Configura√ß√µes**: `config/config.yml`
- **Logs**: `logs/`

**‚úÖ Sucesso!** Seus dados est√£o prontos para alimentar a CNN de classifica√ß√£o musical!