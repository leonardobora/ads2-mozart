# ğŸ¤– Guia do ML Engineer - Projeto Mozart CNN

## VisÃ£o Geral
Como **ML Engineer** do projeto, vocÃª Ã© responsÃ¡vel por implementar, treinar e otimizar a rede neural convolucional (CNN) para classificaÃ§Ã£o de conteÃºdo sensÃ­vel em letras musicais.

---

## ğŸ¯ Suas Responsabilidades

### 1. **Arquitetura da CNN**
- Implementar modelo CNN otimizado para classificaÃ§Ã£o de texto
- Definir camadas de embedding, convoluÃ§Ã£o e pooling
- Configurar arquitetura multi-label para 6 categorias sensÃ­veis

### 2. **Pipeline de Treinamento**
- Configurar processo de treinamento com validaÃ§Ã£o
- Implementar early stopping e checkpointing
- Monitorar mÃ©tricas de performance

### 3. **OtimizaÃ§Ã£o e AvaliaÃ§Ã£o**
- Tuning de hiperparÃ¢metros
- ValidaÃ§Ã£o cruzada temporal
- AnÃ¡lise de performance por categoria

### 4. **Deploy e Monitoramento**
- Preparar modelo para produÃ§Ã£o
- Implementar pipeline de inferÃªncia
- Configurar monitoramento de drift

---

## ğŸš€ Roadmap - ImplementaÃ§Ã£o da CNN

### **FASE 1: PreparaÃ§Ã£o do Ambiente**

**ğŸ”§ DependÃªncias TÃ©cnicas:**
- Aguardar dados rotulados do Data Steward
- Verificar configuraÃ§Ã£o GPU/CPU
- Instalar dependÃªncias ML

**ğŸ“‹ Checklist PrÃ©-Requisitos:**
- [ ] Arquivo `data/labeled/songs_labeled_COMPLETE.csv` disponÃ­vel
- [ ] Pelo menos 800 mÃºsicas anotadas
- [ ] Python 3.8+ com torch instalado
- [ ] Acesso a GPU (recomendado)

### **FASE 2: AnÃ¡lise dos Dados Rotulados**

**ğŸ¯ Objetivos:**
- Entender distribuiÃ§Ã£o dos rÃ³tulos
- Identificar desbalanceamento de classes
- Definir estratÃ©gia de balanceamento

**ğŸ” AnÃ¡lises NecessÃ¡rias:**
- DistribuiÃ§Ã£o por categoria (misogyny, violence, etc.)
- CorrelaÃ§Ã£o entre categorias
- AnÃ¡lise temporal dos rÃ³tulos
- Comprimento mÃ©dio das letras por categoria

**ğŸ“Š MÃ©tricas Esperadas:**
- Pelo menos 50 exemplos positivos por categoria
- DistribuiÃ§Ã£o nÃ£o muito desbalanceada (< 10:1)
- CorrelaÃ§Ã£o moderada entre categorias (< 0.7)

### **FASE 3: Preprocessamento para CNN**

**ğŸ› ï¸ Tarefas de Preprocessamento:**

1. **TokenizaÃ§Ã£o e VocabulÃ¡rio:**
   - Criar vocabulÃ¡rio com 10k palavras mais frequentes
   - Implementar padding para sequÃªncias de 512 tokens
   - Adicionar tokens especiais (UNK, PAD)

2. **Encoding dos Labels:**
   - Multi-hot encoding para 6 categorias
   - EstratÃ©gia para exemplos sem rÃ³tulos positivos
   - Pesos de classe para balanceamento

3. **DivisÃ£o Temporal:**
   - Split por dÃ©cada (nÃ£o aleatÃ³rio)
   - Treino: 1959-2009, Teste: 2010-2019
   - ValidaÃ§Ã£o: 20% do treino (aleatÃ³rio)

### **FASE 4: Arquitetura CNN**

**ğŸ—ï¸ Componentes da Rede:**

1. **Embedding Layer:**
   - DimensÃ£o: 300 (configurÃ¡vel)
   - PrÃ©-treinado: Word2Vec ou GloVe opcional
   - Trainable: True

2. **Convolutional Layers:**
   - Filtros: [2, 3, 4, 5] n-gramas
   - NÃºmero de filtros: 128 por tamanho
   - AtivaÃ§Ã£o: ReLU
   - Dropout: 0.5

3. **Pooling e Classification:**
   - Global Max Pooling para cada filtro
   - ConcatenaÃ§Ã£o dos features
   - Dense layer: 256 â†’ 6 (sigmoid)

**âš™ï¸ ConfiguraÃ§Ãµes TÃ©cnicas:**
- Loss: Binary Cross Entropy (multi-label)
- Optimizer: Adam (lr=0.001)
- Metrics: F1-score, Precision, Recall por categoria
- RegularizaÃ§Ã£o: Dropout + Weight Decay

### **FASE 5: Treinamento e ValidaÃ§Ã£o**

**ğŸ¯ EstratÃ©gia de Treinamento:**

1. **ConfiguraÃ§Ã£o Base:**
   - Batch size: 32
   - Epochs: 50 (com early stopping)
   - Patience: 10 epochs
   - Salvar melhor modelo por F1-score

2. **TÃ©cnicas de RegularizaÃ§Ã£o:**
   - Dropout nas camadas densas
   - Weight decay (L2): 0.01
   - Learning rate scheduling (ReduceLROnPlateau)

3. **ValidaÃ§Ã£o:**
   - ValidaÃ§Ã£o por Ã©poca
   - MÃ©tricas por categoria individual
   - Matriz de confusÃ£o por categoria
   - AnÃ¡lise de casos difÃ­ceis

### **FASE 6: OtimizaÃ§Ã£o de HiperparÃ¢metros**

**ğŸ”¬ Experimentos Planejados:**

1. **Grid Search BÃ¡sico:**
   - Learning rate: [0.01, 0.001, 0.0001]
   - Dropout: [0.3, 0.5, 0.7]
   - Filtros por tamanho: [64, 128, 256]

2. **Arquitetura:**
   - DimensÃ£o embedding: [200, 300, 400]
   - Filtros: [2,3,4], [3,4,5], [2,3,4,5]
   - Pooling: Max vs Average

3. **Dados:**
   - Balanceamento: undersampling vs oversampling
   - Sequence length: [256, 512, 1024]
   - VocabulÃ¡rio: [5k, 10k, 20k]

### **FASE 7: AvaliaÃ§Ã£o Profunda**

**ğŸ“ˆ MÃ©tricas de AvaliaÃ§Ã£o:**

1. **MÃ©tricas Gerais:**
   - F1-score macro e micro
   - Precision/Recall por categoria
   - ROC-AUC para cada categoria
   - Hamming Loss (multi-label)

2. **AnÃ¡lises EspecÃ­ficas:**
   - Performance por dÃ©cada
   - AnÃ¡lise de confusÃ£o entre categorias
   - Casos de falsos positivos/negativos
   - Interpretabilidade (attention maps)

3. **ValidaÃ§Ã£o Temporal:**
   - Performance em dados de dÃ©cadas nÃ£o vistas
   - DegradaÃ§Ã£o temporal do modelo
   - Bias por Ã©poca musical

### **FASE 8: PreparaÃ§Ã£o para ProduÃ§Ã£o**

**ğŸš€ Deploy Pipeline:**

1. **OtimizaÃ§Ã£o do Modelo:**
   - QuantizaÃ§Ã£o (opcional)
   - ONNX export para compatibilidade
   - Benchmark de inferÃªncia

2. **API de PrediÃ§Ã£o:**
   - Interface REST para prediÃ§Ãµes
   - Batch processing para mÃºltiplas mÃºsicas
   - ValidaÃ§Ã£o de input

3. **Monitoramento:**
   - Drift detection nos inputs
   - Performance monitoring
   - Logging de prediÃ§Ãµes

---

## ğŸ“‹ Checklist TÃ©cnico - ML Engineer

### **PreparaÃ§Ã£o** âœ…
- [ ] Dados rotulados recebidos do Data Steward
- [ ] Ambiente de desenvolvimento configurado
- [ ] GPU disponÃ­vel e testada
- [ ] DependÃªncias instaladas

### **ImplementaÃ§Ã£o** âœ…
- [ ] MÃ³dulo de preprocessamento implementado
- [ ] Arquitetura CNN implementada
- [ ] Pipeline de treinamento funcional
- [ ] Sistema de mÃ©tricas configurado

### **ExperimentaÃ§Ã£o** âœ…
- [ ] Baseline CNN treinado
- [ ] HiperparÃ¢metros otimizados
- [ ] ValidaÃ§Ã£o temporal executada
- [ ] RelatÃ³rio de performance gerado

### **ProduÃ§Ã£o** âœ…
- [ ] Modelo final selecionado
- [ ] Pipeline de inferÃªncia testado
- [ ] API de prediÃ§Ã£o implementada
- [ ] Monitoramento configurado

---

## ğŸ› ï¸ Arquivos a Implementar

### **MÃ³dulos Python:**
1. `src/models/cnn_classifier.py` - Arquitetura CNN
2. `src/models/trainer.py` - Loop de treinamento
3. `src/models/evaluator.py` - MÃ©tricas e avaliaÃ§Ã£o
4. `src/features/text_features.py` - Preprocessamento
5. `src/utils/metrics.py` - MÃ©tricas customizadas

### **Scripts de ExecuÃ§Ã£o:**
1. `scripts/train_cnn.py` - Script de treinamento
2. `scripts/evaluate_model.py` - AvaliaÃ§Ã£o do modelo
3. `scripts/hyperparameter_tuning.py` - OtimizaÃ§Ã£o
4. `scripts/export_model.py` - Export para produÃ§Ã£o

### **Notebooks de AnÃ¡lise:**
1. `notebooks/02_model_development.ipynb` - Desenvolvimento
2. `notebooks/03_hyperparameter_tuning.ipynb` - Tuning
3. `notebooks/04_model_evaluation.ipynb` - AvaliaÃ§Ã£o
4. `notebooks/05_error_analysis.ipynb` - AnÃ¡lise de erros

---

## ğŸš¨ DependÃªncias e LimitaÃ§Ãµes

### **DependÃªncias CrÃ­ticas:**
- **Data Steward**: Dados rotulados de qualidade
- **DevOps**: Infraestrutura de treinamento
- **Hardware**: GPU recomendada para treinamento

### **LimitaÃ§Ãµes TÃ©cnicas:**
- Dataset relativamente pequeno (800-1000 mÃºsicas)
- Multi-label classification (mais complexo)
- PossÃ­vel desbalanceamento de classes
- Temporal drift entre dÃ©cadas

### **Riscos e MitigaÃ§Ãµes:**
- **Overfitting**: Usar dropout e validaÃ§Ã£o rigorosa
- **Bias temporal**: ValidaÃ§Ã£o por dÃ©cada
- **Classes raras**: TÃ©cnicas de balanceamento
- **Interpretabilidade**: Implementar attention/saliency

---

## ğŸ“ ComunicaÃ§Ã£o com Equipe

### **Com Data Steward:**
- **Receber**: Dados rotulados, estatÃ­sticas de qualidade
- **Validar**: DistribuiÃ§Ã£o dos rÃ³tulos, consistÃªncia
- **Feedback**: Problemas encontrados nos dados

### **Com DevOps:**
- **Especificar**: Requisitos de hardware/software
- **Integrar**: Pipeline de treinamento automatizado
- **Monitorar**: MÃ©tricas de modelo em produÃ§Ã£o

### **Com Supervisor:**
- **Reportar**: Progress dos experimentos
- **Discutir**: DecisÃµes de arquitetura
- **Apresentar**: Resultados e limitaÃ§Ãµes

---

## ğŸ“š Recursos TÃ©cnicos

### **DocumentaÃ§Ã£o:**
- `config/config.yml` - ConfiguraÃ§Ãµes do modelo
- `docs/model_architecture.md` - Detalhes tÃ©cnicos
- `results/experiments/` - Logs de experimentos

### **ReferÃªncias:**
- Kim, Y. (2014) - "Convolutional Neural Networks for Sentence Classification"
- Zhang, X. (2015) - "Character-level CNNs for Text Classification"
- Papers sobre multi-label text classification

**âœ… VocÃª estÃ¡ pronto para implementar uma CNN robusta para classificaÃ§Ã£o de conteÃºdo musical sensÃ­vel!**